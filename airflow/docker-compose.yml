version: '3.7'
# ====================================== AIRFLOW ENVIRONMENT VARIABLES =======================================
x-environment: &airflow_environment
  - AIRFLOW__CORE__EXECUTOR=LocalExecutor
  - AIRFLOW__CORE__LOAD_DEFAULT_CONNECTIONS=False
  - AIRFLOW__CORE__LOAD_EXAMPLES=True
  - AIRFLOW__CORE__SQL_ALCHEMY_CONN=postgresql://airflow:airflow@postgres:5432/airflow
  - AIRFLOW__CORE__STORE_DAG_CODE=True
  - AIRFLOW__CORE__STORE_SERIALIZED_DAGS=True
  - AIRFLOW__WEBSERVER__EXPOSE_CONFIG=True
  - AIRFLOW__CORE__FERNET_KEY=${FERNET_KEY}
  - AIRFLOW_VAR_DATA_PATH=${DATA_PATH}
  - AIRFLOW_VAR_CURRENT_MODEL_DATE=${CURRENT_MODEL_DATE}
  - AIRFLOW_VAR_MLFLOW_RUNS_PATH=${MLFLOW_RUNS_PATH}


x-airflow-image: &airflow_image apache/airflow:2.3.0-python3.8
# ====================================== /AIRFLOW ENVIRONMENT VARIABLES ======================================
services:
  postgres:
    image: postgres:12-alpine
    environment:
      - POSTGRES_USER=airflow
      - POSTGRES_PASSWORD=airflow
      - POSTGRES_DB=airflow
    ports:
      - "5432:5432"
  init:
    build:
      context: images/airflow-docker
      args:
        AIRFLOW_BASE_IMAGE: *airflow_image
    image: airflow-docker
    depends_on:
      - postgres
    environment: *airflow_environment
    entrypoint: /bin/bash
    command: -c 'airflow db init && airflow users create --username admin --password admin --firstname Anonymous --lastname Admin --role Admin --email admin@example.org'

  webserver:
    build:
      context: images/airflow-docker
      args:
        AIRFLOW_BASE_IMAGE: *airflow_image
    image: airflow-docker

    restart: always
    depends_on:
      - postgres
    ports:
      - "8080:8080"
    volumes:
      - logs:/opt/airflow/logs
    environment: *airflow_environment
    command: webserver

  scheduler:
    build:
      context: images/airflow-docker
      args:
        AIRFLOW_BASE_IMAGE: *airflow_image
    image: airflow-docker

    restart: always
    depends_on:
      - postgres
    volumes:
      - logs:/opt/airflow/logs
      - ./dags/:/opt/airflow/dags/
      - ./data/:/opt/airflow/data/
      - /var/run/docker.sock:/var/run/docker.sock
    environment: *airflow_environment
    command: scheduler

  get-data:
    build:
      context: images/airflow-get-data
    image: airflow-get-data
    restart: "no"

  split-data:
    build:
      context: images/airflow-data-split
    image: airflow-data-split
    restart: "no"

  process-data:
    build:
      context: images/airflow-preprocess
    image: airflow-preprocess
    restart: "no"

  train-data:
    build:
      context: images/airflow-train
    image: airflow-train
    restart: "no"
    network_mode: "host"

  validation:
    build:
      context: images/airflow-validation
    image: airflow-validation
    restart: "no"
    network_mode: "host"

  predict:
    build:
      context: images/airflow-predict
    image: airflow-predict
    restart: "no"
    network_mode: "host"

  mlflow:
    build:
      context: images/mlflow
    image: mlflow
    volumes:
      - ./mlflow_runs/:/mlflow/mlflow_runs/
    ports:
      - "5050:5050"
    restart: always

volumes:
  logs:


# to run docker-compose - ./run.sh